{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "In order to run the code in parallel, we first need to add some julia processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed\n",
    "addprocs(7)\n",
    "nprocs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared memory parallelization of block banded matrices\n",
    "\n",
    "The objective is to parallelize block banded matrices using a shared memory\n",
    "model. Block banded matrices can be parameterized to accept different kinds of\n",
    "storage back-ends. Among other things, it means block banded matrices can be\n",
    "parallelized simply by telling them to use a `SharedArray` as storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin\n",
    "    using Pkg\n",
    "    Pkg.activate(pwd())\n",
    "    using BlockBandedMatrices: BandedBlockBandedMatrix, _BandedBlockBandedMatrix\n",
    "    using BlockBandedMatrices: BandedBlockBandedSizes\n",
    "    using BlockArrays: PseudoBlockArray, Block, nblocks\n",
    "    using SharedArrays: SharedArray\n",
    "\n",
    "    const SharedPseudoBlock = \n",
    "        PseudoBlockArray{T, 2, SharedArray{T, 2}, B} where {T, B}\n",
    "    const SharedBandedBlockBandedMatrix =\n",
    "        BandedBlockBandedMatrix{T, SharedPseudoBlock{T, B}} where {T, B}\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a shared array at the very bottom. It holds the actual data. On it,\n",
    "we layer an abstraction, the `PseudoBlockArray` that allows us to view the\n",
    "shared array as an array of blocks. On top of that, the\n",
    "`BandedBlockBandedMatrix` adds another layer of abstraction to the view the\n",
    "block array as banded matrix of block banded matrices.\n",
    "\n",
    "We can now create an overloaded function to initialize the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function SharedBandedBlockBandedMatrix{T}(\n",
    "        ::UndefInitializer, bs::BandedBlockBandedSizes; kwargs...) where T\n",
    "    shared = SharedArray{T}(size(bs); kwargs...)\n",
    "    block = PseudoBlockArray(shared, bs.data_block_sizes)\n",
    "    _BandedBlockBandedMatrix(block, bs)\n",
    "end\n",
    "\n",
    "@everywhere function SharedBandedBlockBandedMatrix{T}(\n",
    "        ::UndefInitializer,\n",
    "        dims::NTuple{2, AbstractVector{Int}},\n",
    "        lu::NTuple{2, Int},\n",
    "        λμ::NTuple{2, Int};\n",
    "        kwargs...\n",
    ") where T\n",
    "    blocksizes = BandedBlockBandedSizes(dims..., lu..., λμ...)\n",
    "    SharedBandedBlockBandedMatrix{T}(undef, blocksizes; kwargs...)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate this, let's create a banded block banded matrix with blocks\n",
    "composed of 10x10 matrices (`n` and `m`), with the band of blocks from `l` to\n",
    "`u` and each block banded from `λ` to `μ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, n = 2, 3\n",
    "l, u, λ, μ = 1, 0, 0, 2\n",
    "M, m = N + 1, n + 1\n",
    "A = SharedBandedBlockBandedMatrix{Float64}(undef, (repeat([n], N), repeat([m], M)), (l, u), (λ, μ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what we really want to do is to populate the matrix in parallel. We can do\n",
    "this by allocating blocks for each process to write to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin\n",
    "    \"\"\"Populates the shared banded block banded matrix in parallel\"\"\"\n",
    "    function populate!(\n",
    "            block_populate!::Function, A::SharedBandedBlockBandedMatrix)\n",
    "        @sync begin\n",
    "            for (p, proc) in enumerate(procs(A.data.blocks))\n",
    "                @async remotecall_wait(populate!, proc, block_populate!, A, p)\n",
    "            end\n",
    "        end\n",
    "        A\n",
    "    end\n",
    "\n",
    "    \"\"\"Populates the blocks of A that are assigned to process p.\"\"\"\n",
    "    function populate!(\n",
    "            block_populate!::Function, A::SharedBandedBlockBandedMatrix, p)\n",
    "        n = nmutableblocks(A)\n",
    "\n",
    "        m = length(procs(A.data.blocks))\n",
    "        start = (n ÷ m) * (p - 1) + min((n % m), p - 1)\n",
    "        stop = (n ÷ m) * p + min((n % m), p)\n",
    "\n",
    "        k = 0\n",
    "        for i in 1:nblocks(A, 1), j in max(i - A.l, 1):min(i + A.u, nblocks(A, 2))\n",
    "            if k >= stop\n",
    "                break\n",
    "            elseif k >= start\n",
    "                block_populate!(view(A, Block(i, j)), i, j)\n",
    "            end\n",
    "            k += 1\n",
    "        end\n",
    "        A\n",
    "    end\n",
    "\n",
    "    \"\"\"Counts the number of blocks in the mutable bands.\"\"\"\n",
    "    function nmutableblocks(A::SharedBandedBlockBandedMatrix)\n",
    "        n = nblocks(A, 1)\n",
    "        for i in 1:nblocks(A, 1)\n",
    "            n += min(i + A.u, nblocks(A, 2)) - max(i - A.l, 1)\n",
    "        end\n",
    "        n\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code proceeds in a cascade of three steps. First we have a functions to\n",
    "signal workers to start working. Then we have a funtion that will run on each\n",
    "worker process. It simply parcels out the list of mutable blocks in the banded\n",
    "matrix and figures out which are assigned to it's process id. For each assigned\n",
    "block, it then calls the third function in the cascade, to actually populate the\n",
    "given block.\n",
    "\n",
    "Performance-minded users will notice that this simple-minded implementation runs\n",
    "on idle for a fair bit of the loop over blocks. But in practice, this is a small\n",
    "waste compared to latency issues we will soon dive into.\n",
    "\n",
    "The magic happens in the `@sync` for loop. In practice, each `@async` loop item\n",
    "generates a task and schedules it to be sent and executed by a process.  Then,\n",
    "right before exiting the `@sync` code-block, the tasks are sent over to the\n",
    "processes, and the code waits until the tasks are finished running.\n",
    "\n",
    "In practice, usage looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate!(A) do block, i, j\n",
    "    # block: a view of the block to populate\n",
    "    # i, j: indices of the block\n",
    "    for x in 1:size(block, 1), y in max(x - A.λ, 1):min(x + A.μ, size(block, 2))\n",
    "        block[x, y] = 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison we also construct the serial version of populate, as well as a\n",
    "simple scheme to fill blocks with ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function populate!(\n",
    "        A::BandedBlockBandedMatrix, block_populate!::Function)\n",
    "    for i in 1:nblocks(A, 1), j in max(i - A.l, 1):min(i + A.u, nblocks(A, 2))\n",
    "        block_populate!(view(A, Block(i, j)), i, j)\n",
    "    end\n",
    "    A\n",
    "end\n",
    "\n",
    "@everywhere function simplefill!(A::BandedBlockBandedMatrix)\n",
    "    populate!(A) do bk, i, j\n",
    "        for x in 1:size(bk, 1), y in max(x - A.λ, 1):min(x + A.μ, size(bk, 2))\n",
    "            bk[x, y] = 1\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can run benchmarks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "N, n = 8, 3\n",
    "l, u, λ, μ = 1, 2, 0, 1\n",
    "M, m = 6, n\n",
    "A = SharedBandedBlockBandedMatrix{Float64}(undef, (repeat([n], N), repeat([m], M)), (l, u), (λ, μ))\n",
    "nmutableblocks(A)\n",
    "@benchmark simplefill!($A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = BandedBlockBandedMatrix{Float64}(undef, (repeat([n], N), repeat([m], M)), (l, u), (λ, μ))\n",
    "@benchmark simplefill!($B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's not a win for the multi-core team... But we do not always expect a\n",
    "win in every situation. Surely, the performance depends on the size of the\n",
    "matrix? So let's try a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, l, u, λ, μ = 500, 1, 2, 2, 1\n",
    "serial, parallel, Ns = [], [], [10, 50, 100, 150, 200, 300, 500]\n",
    "for N = Ns\n",
    "    A = SharedBandedBlockBandedMatrix{Float64}(\n",
    "            undef, (repeat([n], N), repeat([n], N)), (l, u), (λ, μ))\n",
    "    bench = @benchmark simplefill!($A)\n",
    "    push!(parallel, bench)\n",
    "\n",
    "    B = BandedBlockBandedMatrix{Float64}(\n",
    "            undef, (repeat([n], N), repeat([n], N)), (l, u), (λ, μ))\n",
    "    bench = @benchmark simplefill!($B)\n",
    "    push!(serial, bench)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using VegaLite, DataFrames, Statistics\n",
    "DataFrame(\n",
    "    data = vcat(\n",
    "        getfield.(mean.(serial), :time) ./ 1000,\n",
    "        getfield.(mean.(parallel), :time) ./ 1000,\n",
    "    ),\n",
    "    n = repeat(Ns, 2),\n",
    "    method=vcat(\n",
    "        repeat([:serial], length(Ns)),\n",
    "        repeat([:parallel], length(Ns))\n",
    "    )\n",
    ") |> @vlplot(mark={:line, point=:true}, x=:n, y=:data, color=:method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
